<!DOCTYPE HTML>
<!--
	Alpha by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Problem Statements</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />

	<!--open graph data-->
	<meta property="og:title" content="Genomics PPFL Platform: 2025 Red Teaming Event" />
	<meta property="og:description"
		content="The NIST Privacy Engineering Program has launched the Genomics PPFL Platform: 2025 Red Teaming Event 
			to direct the research community to explore the complex interaction between model utility, privacy interventions 
			such as noise and clipping bounds, data distribution, and resilience to membership and data reconstruction 
			attacks. This will inform consensus guidance on privacy for federated learning collaborations between genomics 
			researchers." />

	<meta property="og:site_name" content="pages.nist.gov/genomics_ppfl" />
	<meta property="og:image" content="https://pages.nist.gov/privacy_collaborative_research_cycle/images/image4.png" />
	<meta property="og:image:alt" content="Genomics PPFL Platform: 2025 Red Teaming Event" />
	<meta property="og:image:width" content="400" />
	<meta property="og:image:height" content="300" />

	<script src="../assets/js/jquery.min.js"></script>
	<script type="text/javascript" src="../nist_js/leave_notice.js"></script>
	<link rel="stylesheet" type="text/css" href="../static/css/NISTLeaveNotice.css" />

	<script type="text/javascript">
		$(document).ready(function () {
			// Mark external (non-nist.gov) A tags with class "external"
			//If the adress start with https and ends with nist.gov
			var re_nist = new RegExp('^https?:\/\/((^\/)*\.)*nist\\.gov(\/|$)');
			//Regex to find address that start with https 
			var re_absolute_address = new RegExp('^((https?:)?\/\/)');
			$("a").each(function () {
				var url = $(this).attr('href');
				if (re_nist.test(url) || !re_absolute_address.test(url)) {
					$(this).addClass('local');
				} else {
					$(this).addClass('external');
				}
			});
			// Add leaveNotice to external A elements 
			$('a.external').leaveNotice({
				siteName: 'GENOMICS_PPFL-2025',
			});
		});
	</script>

	<!-- NIST CSS -->
	<link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css">
	<link rel="stylesheet" href="../static/css/NISTPages.css">
	<link rel="stylesheet" href="../assets/css/main.css" />

	<!-- NIST Javascript -->
	<!-- <script src="https://pages.nist.gov/nist-header-footer/js/jquery-1.9.0.min.js" type="text/javascript" defer="defer"></script> -->
	<script src="https://pages.nist.gov/nist-header-footer/js/nist-header-footer.js" type="text/javascript"
		defer="defer"></script>

</head>

<body class="is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<div id="header-wrap">
			<header id="header" class="alt">
				<div>
					<a style="border-bottom: 0px" href="../index.html">
						<!-- UPDATE OR REMOVE
						<img style="margin-left: 5px; margin-top: 0.45%" width="180px" height="50px"
							src="../images/crc2025logo.png" />
					-->
					</a>
				</div>
                <nav id="nav">
                    <ul>
						<li><a href="../index.html" class="button">Home</a></li>
						<li><a href="problem.html" class="button">Problem Statements</a></li>
						<!-- <li><a href="leaderboard.html" class="button">Leaderboard </a></li> -->
						<li><a href="submit.html" class="button new">Submit</a></li>
						<!-- <li><a href="techniques.html" class="button">Techniques</a></li> -->
						<li><a href="resources.html" class="button">Resources</a></li>
						<li><a href="connect.html" class="button">Connect</a></li>
                    </ul>
                </nav>
			</header>
		</div>

		<!-- Main -->
		<section id="main" class="container">
			<header id="page-header">
				<h2>Problem Statements</h2>
					
					<ul class="actions special">
						<li><a href="../index.html" class="button">Home</a></li>
						<li><a href="problem.html" class="button primary">Problem Statements</a></li>
						<!-- <li><a href="leaderboard.html" class="button">Leaderboard </a></li> -->
						<li><a href="submit.html" class="button new">Submit</a></li>
						<!-- <li><a href="techniques.html" class="button">Techniques</a></li> -->
						<li><a href="resources.html" class="button">Resources</a></li>
						<li><a href="connect.html" class="button">Connect</a></li>
					</ul>

			</header>
			<div class="box participate separators">
				<section>
				
					<h3>Quick Links (this page):</h3>
					<ul>
						<li><a href="#phase-1">Phase 1: Soybean Data ("Don't Spill the Beans!)</a></li>
						<li><a href="#problem-1">Problem I: Membership Inference Attack [March - April]</a></li>
						<li><a href="#challenge">Red Team Challenge Problem</a></li>
					</ul>

						<h3>2025 Privacy Red Team Calendar of Events</h3>

						Teams are welcome to <a href="https://docs.google.com/forms/d/e/1FAIpQLSetiG9peeMymzA476T8QEH2Mff8_1Q9gmldBmiF4dyff3L4mA/viewform">register</a> at any point during the exercise and <a href="submit.html">submit</a> an entry for any problem. 
						Participating in Phase 1 isn't required for participating in Phase 2.
						<br><br>
					<img src="../images/ppfl calendar.png" height="375">
					<!-- 
					<table>
						<thead>
						  <tr>
							<th scope="col">Start</th>
							<th scope="col">End</th>
							<th scope="col">Program</th>
							<th scope="col">Thing</th>
						  </tr>
						</thead>
						<tbody>
						  <tr>
							<th scope="row">10 Mar 2025</th>
							<td>---</td>
							<td>CRC + PPFL</td>
							<td>Webinar</td>
						  </tr>
						  <tr>
							<th scope="row">10 Mar 2025</th>
							<td>May 1</td>
							<td>PPFL</td>
							<td>Red team phase 1 Problem 1</td>
						  </tr>
						  <tr>
							<th scope="row">1 April 2025</th>
							<td>---</td>
							<td>PPFL</td>
							<td>Deadline for Phase 1 Problem 1 Intermediate Leaderboard Update</td>
						  </tr>
						  <tr>
							<th scope="row">10 April 2025</th>
							<td>May 1</td>
							<td>PPFL</td>
							<td>Red team phase 1 Problem 2</td>
						  </tr>
						  <tr>
							<th scope="row">1 May 2025</th>
							<td>---</td>
							<td>PPFL</td>
							<td>Deadline for Phase 1 Problem 1 & 2 Final Leaderboard Updates</td>
						  </tr>
						  <tr>
							<th scope="row">9 May 2025</th>
							<td>June 30</td>
							<td>PPFL</td>
							<td>Red team phase 2 Problem 1</td>
						  </tr>
						  <tr>
							<th scope="row">30 May 2025</th>
							<td>---</td>
							<td>PPFL</td>
							<td>Deadline for Phase 2 Problem 1 Intermediate Leaderboard Update</td>
						  </tr>
						  <tr>
							<th scope="row">9 June 2025</th>
							<td>June 30</td>
							<td>PPFL</td>
							<td>Red team phase 2 Problem 2</td>
						  </tr>
						  <tr>
							<th scope="row">30 June 2025</th>
							<td>---</td>
							<td>PPFL</td>
							<td>Deadline for Phase 2 Problem 1 & 2 Final Leaderboard Update </td>
						  </tr>
						</tbody>
					  </table>
					-->
				<hr>

				<h3 id="phase-1">Phase 1: Soybean Data ("Don't Spill the Beans!")</h3>
				<p>The first problem we’re addressing is at the first Privacy Barrier in the federated learning pipeline: 
					the Untrusted Central Model.   In each round of federated model training, clients submit  parameter 
					updates based on their private local data.  The central model collects these and uses them to update 
					its model of the full population. The central model then shares its update with the clients, and the 
					process repeats until the central model is fully trained.   
					
					<br><br>
					During this process the clients should retrain full rights and privacy for their individual records.  
					But what if the central aggregator could attack the client model updates to learn about their  
					individual records?  Do clients need to use privacy protection like differential privacy to ensure 
					their model updates don’t reveal too much?   How much protection do they need? 
				
					<p>
						<img src="../images/FL privacy barriers.png" height="350">
					</p>

					<b>In the Phase 1- Basic Problem</b>, running now, we’ll look at a minimally invasive attack: membership inference.   Can an 
					attacker at the central aggregator use the client models to correctly infer whether a record belonged 
					to a given client’s private data set?  

					<br><br>
					<b>In the Phase 1- Advanced Problem</b>, releasing in April, we’ll look at a much more invasive attack: reconstruction. Can 
					an attacker use the	transcript of federated model parameter updates to reconstruct the original data 
					for each client?
				</p>

				<h3 id="problem-1">Phase 1- Basic Problem: Membership Inference Attack [March - April]</h3>
				<p>
					<b>Research Questions:</b> In this problem we focus on the worst case scenario for membership inference: what happens 
					when the clients submit fully trained, potentially overfit local models to the untrusted central party? We want 
					to explore the following important questions: 

					<ul>
						<li>Are the regular CNN’s vulnerable to membership inference attacks? </li>
						<li>Can differential privacy help protect client data?</li>
						<li>Can it help even if epsilon is so large that the added privacy noise doesn’t affect the overall utility?</li>
						<li>Different clients have different local data distributions– does the effectiveness of differential privacy differ 
							for different clients? </li>
					</ul>
					
					<br>
					<b>Machine Learning Data and Task:</b> The task the models are trained to do here is predict seed color for soy bean plants. 
					The columns in the data have been reduced to the gene variants most relevant for this task.   
					
					<br><br>
					Look below for an example of gene variant data.  Each column represents a gene, and the value of the column indicates 
					whether a given plant’s gene varies from the “default” value. For instance the value  “A/T” indicates that the default 
					value of the gene is “A”, but instead this plant has value “T”. Some genes vary from default more than others, and 
					different variants may have more or less importance for the plant’s visible properties. Note that the soybean records in 
					the competitor's pack have been processed into a binary format ("one hot encoding") to make them easier for the models to 
					work with; they're more machine readable and less human readable than the raw data below. 
					
					<br><br>
					<IMG SRC="../images/rawgenomicdataphoto.png" height="255">					
					<br><br>
					Each problem during the exercise will focus on a different task; the data and models here are focused on predicting 
					seed coat color.  The overall distribution of seed color labels in the population as a whole looks like this:  
					
					<br><br>
					<img src="../images/seedcolorhistogram.png" height="450">
					
					<br><br>
					<b>Executing a Membership Inference Attack:</b>

					<br><br>
					Membership inference attacks in general operate by training an attack model to predict whether a record belongs to a
					 given model’s training data.  The idea is that the targeted model will have better confidence and accuracy on records 
					 it was trained on, as compared to records it hasn’t seen before.  This is more likely to be true if the training data 
					 is very small or the model fit its data very closely.   
					
					 <br><br>
					Added noise can help prevent overfitting and reduce the risk of membership inference attacks.   But it’s not clear how 
					much noise is enough, and since added noise can reduce (or eliminate) the utility of clients with smaller data sets, we 
					don’t want to add more noise than we have to.  That’s what you’ll help us explore in this problem.  
					
					<br><br>
					<u>We have three sets of client models for you to attack:</u>
					
					<br><br>
					<ul>
						<li><b>CNN:</b> These client models have no added noise, and were trained for 100 epochs</li>
						<li><b>High Privacy DP:</b> These client models have noise added during the training process, with privacy loss parameter epsilon 
							set to 10, clipping at 2.0, and were trained for 100 epochs.  They should be very private, but the added noise reduces 
							their utility on the seed coat color task, especially for smaller clients. </li>
						<li><b>Low Privacy DP:</b> These client models have noise added with privacy parameter epsilon= 200, clipping at 2.0, trained for 
							100 epochs.  They perform nearly as well on the task as the regular CNN, but since so little noise is added, are they 
							really private? </li>
					</ul>
					
					In order to make an attack model, you need data to train it on.  The attacker doesn’t have access to the original client 
					data, of course, but in the real world they might be able to buy similar, overlapping data sets from a data broker.   
					
					<br><br>
					<u>For each client model we will provide you with two sets of records to help train your attack:</u> 
					<br><br>
					<ul>
						<li><b>Relevant Records:</b> These complete records (including correct seed coat color label) are similar to the clients training 
							data, but might or might not have been actually included in the client’s training data.  /li>
						<li><b>External Records:</b> These complete records (including correct seed coat color label) are guaranteed to have not been 
							included in the client’s training data. </li>
					</ul>
					<br>
					<p>
						<img src="../images/federated membership inference attack problem design.png" height="450">
					</p>

					You can use the relevant and external records, combined with predictions from the client model, to train a separate attack for each 
					client.  Accurate, high confidence predictions are more likely to refer to members of the client’s training data.  Note that this is 
					a realistic attack scenario; the relevant records include real client member records, but they also include some other records that 
					are not members.  The external records are guaranteed to not be client records for the target client. 

					<br><br>
					How precisely do you train an attack model?   Check out our resources page for libraries and references, and our techniques page to 
					see what other participants have tried. 

					<br><br>
					<h3 id="challenge">Red Team Challenge Problem</h3>
					<p>
					You can find a link to the competitors pack with everything you need to prepare a submission on the <a href="submit.html">Submit</a> page.
					<br><br>
					For each of our three privacy settings (CNN, DPLowPrivacy, DPHighPrivacy) we’ll provide the following (see Federated Membership 
					Inference Attack Design diagram above): 

					<ul>
						<li><b>Client models 1, 2, 3, 4.</b> These represent the worst case for privacy, overtrained local models that the untrusted central 
							aggregator might be able to attack. Like real world clients, they have different data distributions. Some may be easier to 
							attack and some may be harder. </li>
						<li><b>Relevant records and External records for each client.</b> This is data you can use to train your attack model, see Executing 
							a Membership Attack for more information. </li>
						<li><b>Challenge Records.</b> These are the records we want you to attack.  Each record has a unique index number.   For each record, predict 
							whether it belongs to client 1, 2, 3, 4 or write 0 if none of the above.</li>
					</ul>

					We also provide a demonstration notebook that walks through a simple membership inference attack on Client 4, along with  example submission 
					files.
					
					<br><br>
					<h3 id="format">Submission format:</h3> 
					
					For each of the three privacy settings, submit a Challenge Record Prediction csv file with the challenge record index number and your prediction 
					for which client it belongs to: 1, 2, 3, 4 or 0 for none.
						
					<br><br>
					<img src="../images/example-submission-file.png" height="160">
						
					<br><br>
					We’ll also ask you for any references (papers, libraries, etc) relevant to your submission, a short description of your approach, an 
					estimate of the computation time/power needed for your approach, and whether you’d like to be included in our Techniques showcase.  
						
					<br><br>
					<h3 id="schedule">Submission schedule:</h3>
					
					The basic problems in each phase are intended to help you get a feel for the data set. For this reason we give you two opportunities to 
					submit to the leaderboard on the basic problems: an intermediate leaderboard update and a final leaderboard update.   Submit your 
					predictions for the challenge records by the deadline, and you’ll get back a percentage accuracy on the leaderboard.
					
					<br><br>
					<b><i>Note you can submit up to three attempts for every leaderboard update deadline</i></b>, using different approaches/configurations. 
					Your team will be scored by your highest performing entry. This gives you a chance to try out multiple libraries or ideas.
					
					<br><br>
					<ul>
						<li>April 1st: Intermediate Leaderboard Deadline (Basic Problem, Phase 1)</li>
						<li>May 1st: Final Leaderboard Deadline (Basic Problem, Phase 1) </li>
					</ul>
						
					<br>
					We’ll be rating different attack libraries by how successful they are, and sharing what we learn about the overall privacy protection 
					of different client models. The goal here isn’t just to get at the top of the leaderboard, it’s to find out together in a realistic 
					setting how attacks behave, and how safe these models really are.    
					
					<br><br>
					<h3 id="practice">Practice data:</h3>  

					In each problem we'll provide you with some demonstration data; essentially a part of the problem where we give you the answers for 
					free, so you can try out different techniques locally before you submit. In the Phase I Basic Problem the competitor's pack includes 
					the membership list for Client 4.
				</p>

				</section>
		</section>
			</div>
	</div>

	<!-- Scripts -->
	<script src="../assets/js/jquery.dropotron.min.js"></script>
	<script src="../assets/js/jquery.scrollex.min.js"></script>
	<script src="../assets/js/browser.min.js"></script>
	<script src="../assets/js/breakpoints.min.js"></script>
	<script src="../assets/js/util.js"></script>
	<script src="../assets/js/main.js"></script>

</body>

</html>
